{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W271 Lab 1\n",
    "\n",
    "## Part I: Marginal, Joint, and Conditional Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 (6 Points)\n",
    "\n",
    "In a team of data scientists, 36 are expert in machine learning, 28 are expert in statistics, and 18 are awesome. 22 are expert in both machine learning and statistics, 12 are expert in machine learning and are awesome, 9 are expert in statistics and are awesome, and 48 are expert in machine learning or statistics or are awesome. Suppose you have a cocktail party with this group of data scientists and you have an equal probability of meeting any one of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. What is the probability of meeting a data scientist who is an expert in both machine learning and statistics and is awesome?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"HW1.1-venn.png\">\n",
    "\n",
    "Let A = Awesome, M = Machine Learning Expert and S = Statistics Expert\n",
    "Given:\n",
    "\n",
    "$A=18, S=28, M=36$\n",
    "\n",
    "$(A \\cap S)=9, (A \\cap M)=12, (S \\cap M)=22$\n",
    " \n",
    "Assuming that there are no team members that don't have these attributes then:\n",
    "$(A \\cup S \\cup M) = 48$\n",
    "\n",
    "$(A \\cup S \\cup M) = A + S + M - (A \\cap S) - (A \\cap M) - (S \\cap M) + (A \\cap S \\cap M)$\n",
    "\n",
    "$48 = 18 + 28 + 36 - 9 - 12 - 22 + (A \\cap S \\cap M)$\n",
    "\n",
    "$(A \\cap S \\cap M) = 9$\n",
    "\n",
    "-------------------------\n",
    "\n",
    "We can also say that\n",
    "\n",
    "$M = (M \\cap S) + (M \\cap A) - (A \\cap S \\cap M) + m$\n",
    "\n",
    "$36 = 22 + 12 - 9 + m \\Rightarrow m = 11$\n",
    "\n",
    "$S = (S \\cap M) + (S \\cap A) - (A \\cap S \\cap M) + s$\n",
    "\n",
    "$28 = 22 + 9 - 9 + s  \\Rightarrow s = 6$\n",
    "\n",
    "$A = (A \\cap M) + (A \\cap S) - (A \\cap S \\cap M) + a$\n",
    "\n",
    "$18 = 12 + 9 - 9 + a  \\Rightarrow a = 6$\n",
    "\n",
    "$Pr(A=a,M=m,S=s) = 9/48$\n",
    "\n",
    "**The probability of meeting a datascientist who is an expert in machine learning, statistics and is awesome is $\\displaystyle \\color{red}{\\frac{3}{16}}$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Suppose you meet a data scientist who is an expert in machine learning. Given this information, what is the probability that they are not awesome?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\displaystyle Pr(\\bar A \\mid M) = Pr(A \\bar M)/Pr(M) = \\frac{24}{36} = \\color{red}{\\frac{2}{3}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Suppose you meet a data scientist who is awesome. Given this information, what is the probability that they are an expert in either machine learning or statistics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\displaystyle Pr(M \\cup S \\mid A) = \\frac{3 + 9 + 0}{18} = \\frac{12}{18} = \\color{red}{\\frac{2}{3}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2  (4 Points)\n",
    "\n",
    "Suppose for events $A$ and $B$, $\\displaystyle Pr(A) = p <= \\frac{1}{2}, Pr(B) = q$, where $\\displaystyle \\frac{1}{4} < q < \\frac{1}{2}$. These are the only information we have about the events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. What are the maximum and minimum possible values for $Pr(A \\cup B)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### specify the conditions and use interval notation \n",
    "\n",
    "It depends on whether A and B are independent (overlap). If they are not independent, then:\n",
    "\n",
    "$$Pr(A \\cup B) = Pr(A) + Pr(B) - Pr(AB)$$\n",
    "\n",
    "Since $Pr(A)$ can range from $0$ to $\\frac{1}{2}$ the lowest value for $Pr(A \\cup B)$ is $$0 + \\lim_{\\delta\\to0}(\\frac{1}{4}+\\delta) - 0 \\times \\lim_{\\delta\\to0}(\\frac{1}{4}+\\delta) = \\frac{1}{4}$$\n",
    "\n",
    "At $$Pr(A) = \\frac{1}{2} \\text{ and } Pr(B) = q = \\lim_{\\delta\\to0}(\\frac{1}{2} - \\delta)$$\n",
    "we have the high value of $$\\frac{1}{2} + q - (\\frac{1}{2} q) = \\frac{1}{2} + \\frac{1}{2} \\lim_{\\delta\\to0}(\\frac{1}{2} - \\delta)$$\n",
    "\n",
    "If $A$ and $B$ are dependent, ${\\frac{1}{4} <= Pr(A \\cup B) < \\frac{5}{8}$\n",
    "\n",
    "Otherwise, if A and B are independent, then:\n",
    "\n",
    "$Pr(A \\cup B) = Pr(A) + Pr(B)$ so at the low end we would have $0 + \\lim_{\\delta\\to0}(\\frac{1}{4}+\\delta)$ and at the high end $\\frac{1}{2}+\\lim_{\\delta\\to0}(\\frac{1}{2} - \\delta)$\n",
    "\n",
    "If $A$ and $B$ are independent, $0 \\leq Pr(A \\cup B) < 1$.\n",
    "\n",
    "Therefore the full range for is $$\\color{red}{{0} \\leq Pr(A \\cup B) < {1}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What are the maximum and minimum possible values for $Pr(A|B)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we don't know anything about the independence of A and B.\n",
    "\n",
    "If A and B are not independent:\n",
    "\n",
    "$\\displaystyle Pr(A \\mid B)$ $\\displaystyle= \\frac{Pr(AB)}{Pr(B)}$ and since $Pr(A)$ can be $0$ the lower bound is $0$\n",
    "\n",
    "If $A$ is contained in $B$ then the probability is $\\lim_{\\delta\\to0} (1-\\delta)$.\n",
    "\n",
    "Therefore the range of $Pr(A|B)$ is $$\\color{red}{0 \\leq Pr(A|B) < 1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Random Variables, Expectation, Conditional Expectation\n",
    "\n",
    "### Question 3 (6 Points)\n",
    "\n",
    "Suppose the life span of a particular server is a continuous random variable, $t$, with a uniform probability distribution between $0$ and $k$ years, where $k \\leq 10$ is a positive integer.\n",
    "\n",
    "The server comes with a contract that guarantees a full or partial refund depending on how long it lasts. Specifically, if the server fails in the first year it gives a full refund denoted by $\\theta$. If it lasts more than $1$ year but fails before $\\frac{k}{2}$ years, the manufacturer will pay $x = A(k-t)^\\frac{1}{2}$, where A is some positive constant equal to $2$ if $t \\leq \\frac{k}{2}$. If it lasts between $\\frac{k}{2}$ and $\\frac{3k}{4}$ years, it pays $\\frac{\\theta}{10}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Lab1-Q3.1.png\" width=400>\n",
    "\n",
    "Probability distribution function is: $f(t) = \\begin{cases} \n",
    "      0 & t\\leq 0 \\\\\n",
    "      \\frac{1}{k} & 0\\leq t\\leq k \\\\\n",
    "      0 & t > k \n",
    "   \\end{cases}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Given that the server lasts for $\\frac{k}{4}$ years without failing, what is the probability that it will last another year?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Pr(t=\\frac{k}{4}+1 \\mid t=\\frac{k}{4}) = \\displaystyle \\int_{t=\\frac{k}{4}}^{t=\\frac{k}{4}+1} \\frac{1}{k} dt = \\frac{t}{k} \\displaystyle \\bigr|_{t=\\frac{k}{4}}^{t=\\frac{k}{4}+1} = \\frac{\\frac{k}{4}+1}{k} - \\frac{\\frac{k}{4}}{k} = \\frac{1}{k}(\\frac{k}{4}+1)-\\frac{1}{k}\\frac{k}{4}$$ \n",
    "$$= \\frac{1}{4}+\\frac{1}{k}-\\frac{1}{4} = \\color{red}{\\frac{1}{k} \\text{ for } k \\geq \\frac{4}{3}} $$\n",
    "\n",
    "When $k < \\frac{4}{3}$: since $k$ is an integer, $k = 1$.\n",
    "\n",
    "Therefore $$P(\\text{server lives 1 year}) = \\int_{t=\\frac{1}{4}}^{t=1} 1 dt = t\\big|_\\frac{1}{4}^{1} = 1 - \\frac{1}{4} = \\frac{3}{4}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Compute the expected payout from the contract, $E(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$E[x] = \\begin{cases}\n",
    "      \\theta & 0\\leq t\\leq 1 \\\\\n",
    "      A(k - t)^\\frac{1}{2} & 1 < t \\leq \\frac{k}{2} \\\\\n",
    "      \\frac{\\theta}{10} & \\frac{k}{2} < t\\leq \\frac{3k}{4} \\\\\n",
    "      0 & t > \\frac{3k}{4} \n",
    "   \\end{cases}$\n",
    "   \n",
    "For $\\displaystyle 0 \\leq t \\leq 1$ we have:\n",
    "$$\\displaystyle E[x] = \\theta \\times Pr(t \\leq 1) = \\theta \\int_{t=0}^{t=1} \\frac{1}{k} dt = \\color{red}{\\frac{\\theta}{k}}$$\n",
    "\n",
    "#### See Subhashimi's notes for this one\n",
    "\n",
    "For $1 < t \\leq \\frac{k}{2}$ we have:\n",
    "$$ \\displaystyle E[x] = \\displaystyle \\int_{t=1}^{t=\\frac{k}{2}} 2(k-t)^{\\frac{1}{2}}\\frac{1}{k}dt = \\frac{2}{k} \\int_{t=1}^{t=\\frac{k}{2}} (k-t)^{\\frac{1}{2}} dt $$\n",
    "\n",
    "$$= \\frac{-4}{3k}(k-t)^{\\frac{3}{2}} \\bigg|_{t=1}^{t=\\frac{k}{2}}$$\n",
    "\n",
    "$$\\color{red}{= \\frac{4}{3k}\\bigg[(k-1)^{\\frac{3}{2}} - \\big(\\frac{k}{2}^\\frac{3}{2}\\big)\\bigg]}$$\n",
    "\n",
    "\n",
    "\n",
    "For $\\displaystyle \\frac{k}{2} < t < \\frac{3k}{4}$ we have:\n",
    "$$\\displaystyle E[x] = \\frac{\\theta}{10} \\int_{t=\\frac{k}{2}}^{t=\\frac{3k}{4}} \\frac{1}{k} dt$$\n",
    "\n",
    "$$\\displaystyle = \\frac{\\theta}{10} \\frac{t}{k}\\bigg|_{\\frac{k}{2}}^{\\frac{3k}{4}}$$\n",
    "\n",
    "$$=\\displaystyle \\frac{\\theta}{10}(\\frac{3}{4} - \\frac{1}{2}) = \\color{red}{\\frac{\\theta}{40}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Compute the variance of the payout from the contract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Var(x) = E[x^2] - E[x]^2$\n",
    "\n",
    "For $\\displaystyle 0 \\leq t \\leq 1$ we have:\n",
    "$$\\displaystyle E[x^2] = \\int_{t=0}^{t=1} \\theta^2 \\frac{1}{k} dt = \\frac{\\theta^2}{k}$$\n",
    "From the previous problem:\n",
    "$$\\displaystyle E[x] = \\frac{\\theta}{k}$$\n",
    "Therefore:\n",
    "$$\\displaystyle Var(x) = E[x^2]-E[x]^2 = \\frac{\\theta^2}{k} - (\\frac{\\theta}{k})^2 = \\color{red}{\\frac{\\theta^2}{k}\\big(1-\\frac{1}{2} \\big)}$$\n",
    "\n",
    "For $\\displaystyle 1 < t \\leq \\frac{k}{2}$ we have:\n",
    "$$\\displaystyle E[x^2] = \\int_{t=1}^{\\frac{k}{2}} 2(k-t)^2 \\frac{1}{k}dt = \\frac{4}{k}\\int_{t=1}^{t=\\frac{k}{2}}(k-t)^2dt $$\n",
    "\n",
    "$$\\displaystyle = \\frac{4}{k}\\bigg(\\frac{-t^2}{2}\\bigg|_{t=1}^{t=\\frac{k}{2}} + tk\\bigg|_{1}^{\\frac{k}{2}}\\bigg) = \\frac{4}{k}\\bigg(\\frac{-1}{2}\\big(\\frac{k^2}{4}-1\\big) + k\\big(\\frac{k}{2}-1\\big)\\bigg) = \\frac{4}{k}\\bigg(\\frac{-k^2}{8} + \\frac{1}{2}+\\frac{k^2}{2}-k\\bigg)$$\n",
    "\n",
    "Therefore $$\\displaystyle E[x^2] = \\frac{3k}{2} + \\frac{2}{k} - 4$$\n",
    "\n",
    "From earlier results we can calculate $E[x]^2$:\n",
    "$$\\Bigg(\\frac{4}{3k}\\bigg[\\bigg(\\bigg(k-1\\bigg)^{\\frac{3}{2}} - \\frac{k}{2}\\bigg)^{\\frac{3}{2}}\\bigg]\\Bigg)^2 = \\frac{16}{9k^2}\\Bigg[(k-1)^{{2}\\times\\frac{3}{2}} - 2(k-1)^\\frac{3}{2}\\big(\\frac{k}{2}\\big)^\\frac{3}{2} + \\big(\\frac{k}{2}\\big)^{2\\times\\frac{3}{2}}\\Bigg]$$\n",
    "\n",
    "$$\\displaystyle = \\frac{16}{9k^2}\\bigg[(k-1)^3 -2(k-1)^\\frac{3}{2}\\big(\\frac{k}{2}\\big)^\\frac{3}{2} + \\big(\\frac{k}{2}\\big)^3 \\bigg]$$\n",
    "\n",
    "$$\\displaystyle = \\frac{16}{9k^2}(k-1)^3 - \\frac{2^\\frac{7}{2}}{9k^\\frac{1}{2}}(k-1)^\\frac{3}{2} + \\frac{2k}{9}$$\n",
    "\n",
    "Therefore:\n",
    "$$\\displaystyle Var(X) = E[X^2] - E[X]^2 = \\frac{3k}{2} + \\frac{2}{k} - 4 -\\bigg[\\frac{16}{9k^2}(k-1)^3 - \\frac{2^\\frac{7}{2}}{9k^\\frac{1}{2}}(k-1)^\\frac{3}{2} + \\frac{2k}{9} \\bigg]$$\n",
    "\n",
    "$$\\displaystyle = \\frac{3k}{2}k + \\frac{2}{k} - 4 - \\frac{16}{9k^2}(k-1)^3 + \\frac{2^\\frac{7}{2}}{9k^\\frac{1}{2}}(k-1)\\frac{3}{2} - \\frac{2k}{9}$$\n",
    "\n",
    "$$\\displaystyle \\color{red}{Var(X) = \\frac{23}{18}k + \\frac{2}{k} - \\frac{16}{9k^2}(k-1)^3 + \\frac{2^\\frac{7}{2}}{9k^\\frac{1}{2}}(k-1)\\frac{3}{2} - 4}$$\n",
    "\n",
    "For $\\displaystyle \\frac{k}{2} < t < \\frac{3k}{4}$ we have:\n",
    "$$\\displaystyle E[x^2] = \\int_{t=\\frac{k}{2}}^{t=\\frac{3k}{4}} \\big(\\frac{\\theta}{10})^2 \\frac{1}{k} dt = \\frac{\\theta^2}{100}\\big[\\frac{3k}{4} - \\frac{k}{2} \\big] = \\frac{\\theta^2}{100} \\frac{1}{4} k = \\frac{\\theta^2}{400}$$\n",
    "\n",
    "Using E[X] from previous results we have:\n",
    "$$Var(x) = E[x^2]-E[x]^2 = \\frac{\\theta^2}{400} - \\bigg(\\frac{\\theta}{40}\\bigg)^2 = \\color{red}{\\frac{3}{1600}\\theta^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4  (9 Points)\n",
    "\n",
    "Continuous random variables $X$ and $Y$ have a joint distribution with probability density function \n",
    "$$f(x,y) = 2e^{-x}e^{-2y} \\begin{cases}\n",
    "      0 \\leq x\\leq \\infty \\\\\n",
    "      0 \\leq y \\leq \\infty \n",
    "   \\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Compute $P(X > a,Y < b)$, where $a,b$ are positive constants and $a < b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Pr(X>a,Y<b) = \\int_{y=0}^{y=b} \\int_{x=a}^{x=\\infty} 2e^{-x}e^{-2y}dx dy = \\int_{y=0}^{y=b}e^{-2y}dy \\int_{x=a}^{x=\\infty} 2e^{-x}dx$$\n",
    "\n",
    "$$= -\\frac{1}{2}e^{-2y}\\bigg|_{y=0}^{y=b}  2(-e^{-x})\\bigg|_{x=a}^{\\infty} = (-e^{-2y})\\bigg|_{y=0}^{y=b}  (-e^{-x})\\bigg|_{x=a}^{\\infty}$$\n",
    "\n",
    "$$=(-e^{-2b} + \\frac{1}{2}) (0 + e^{-a})$$\n",
    "$$\\color{red}{= e^{-a} - e^{-a-2b}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Compute $P(X < Y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Pr(X < Y) = \\int_{y=0}^{y=\\infty} \\int_{x=0}^{x=y} 2e^{-x}e^{-2y}dx dy$$\n",
    "\n",
    "$$= 2\\int_{y=0}^{y=\\infty} \\big(-e^{-y}+1 \\big) e^{-2y}dy = 2\\int_{y=0}^{y=\\infty} -e^{-3y}+e^{-2y} dy$$\n",
    "\n",
    "$$=2(\\frac{e^{-3y}}{3}-\\frac{e^{-2y}}{2})\\bigg|_{y=0}^{y=\\infty}=\\color{red}{\\frac{1}{3}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Compute $P(X < a)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Pr(X < a) = \\int_{x=0}^{x=a} \\int_{y=0}^{y=\\infty} 2e^{-x}e^{-2y}dxdy = e^{-x}\\bigg|_{x=0}^{x=a}e^{-2y}\\bigg|_{y=0}^{y=\\infty} \\color{red}{=1-e^{-a} }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 (6 Points)\n",
    "\n",
    "#### 1. Find the value of x that minimizes E(Y). Show that your result is really the minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first expand the definition of $Y$:\n",
    "\n",
    "$$Y=a+b(X-x)^2=a+bx^2+bX^2-2bxX$$\n",
    "\n",
    "then $E(Y)$ becomes:\n",
    "\n",
    "$$E(Y)=a+bx^2+bE(X^2)-2bxE(X)$$\n",
    "\n",
    "to find the $x$ that minimums $E(Y)$, we take derivative with respect to $x$:\n",
    "\n",
    "$$\\frac{dE(Y)}{dx}=2bx-2bE(X)$$\n",
    "\n",
    "set it to $0$ and we will find the $x$ that minimizes $E(Y)$:\n",
    "\n",
    "$$\\color{red}{x=E(Y)}$$\n",
    "\n",
    "Geometrically, by subtracting $E(X)$ from X we move the whole population of $X$ around zero, which will give the minimum square value of the population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Find the value of E(Y) for the choice of x you found in (1)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plug in $x=E(X)$ into the formula of $E(Y)$, we have:\n",
    "\n",
    "$$E(Y)=a+bE(X)^2+bE(X^2)-2bE(X)^2=a+b(E(X^2)-E(X)^2)$$\n",
    "\n",
    "and we have\n",
    "\n",
    "$$\\color{red}{E(Y)_{min}=a+bVar(X)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Suppose $Y = ax + b(X − x)^2$. Find the values of $x$ that minimizes $E(Y)$. Show that your result is really the minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to part \\#1, we first obtain the new $E(Y)$:\n",
    "\n",
    "$$E(Y)=ax+bx^2+bE(X^2)-2bxE(X)$$\n",
    "\n",
    "take derivative of $E(Y)$:\n",
    "\n",
    "$$\\frac{dE(Y)}{dx}=a+2bx-2bE(X)$$\n",
    "\n",
    "set it to zero, we have the $x$ that minimums $E(Y)$\n",
    "\n",
    "$$x=E(X)-\\frac{a}{2b}$$\n",
    "\n",
    "plug $x$ into $E(Y)$, and the minimum is:\n",
    "\n",
    "$$\\color{red}{E(Y)_{min}=aE(X)+bVar(X)-\\frac{a^2}{2b}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6 (4 Points)\n",
    "\n",
    "Suppose $X$ and $Y$ are independent continuous random variables where both are uniformly distributed between $0$ and $1$. Let random variable $Z = X + Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Choose a value of $z$ between $0$ and $2$, and draw a graph depicting the region of the $X − Y$ plane for which $Z$ is less than $z$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Derive the probability density function, $f(z)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f(x) = f(y) = \\begin{cases}\n",
    "              0 & x < 0 \\\\\n",
    "              1 & 0\\leq x \\leq 1 \\\\\n",
    "              0 & x > 1\n",
    "           \\end{cases}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7 (10 Points)\n",
    "\n",
    "In a casino, you pay the following game. A pair fair, ordinary 6-faced dices is rolled. If the sum of the dice is 2,3,or 12, the house wins. If it is 7 or 11, you win. If it is any other number x, the house rolls the dice again until the sum is either 7 or x. If it is 7, the house wins. If it is x, you win. A game ends if one of the two players wins. Let Y be the number of rolls needed until the game ends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Is the expected number of rolls given that you win more than, equal to, or less than the expected number of rolls given that house wins (in a game)? The steps to arrive at your answer numerically need to be clearly shown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's say that $h = \\{2, 3, 12\\}$, $y = \\{7, 11\\}$ and $x = \\{4, 5, 6, 8, 9, 10\\}$ such that on any roll of the dice, the result will be either a value in $h$, $y$, or $x$.\n",
    "\n",
    "We can calculate probabilities: $P(h) = P(2)+P(3)+P(12), P(y) = P(7)+P(11), \\text{and } P(x) = P(4)+P(5)+P(6)+P(8)+P(9)+P(10)$\n",
    "\n",
    "$P(h) = \\frac{4}{36}  P(y) = \\frac{8}{36}  P(x) = \\frac{24}{36} \\text{and } P(h)+P(y)+P(x) = 1$\n",
    "\n",
    "$P(7) = \\frac{6}{36}$\n",
    "\n",
    "The rolls on which the house can win are:\n",
    "\n",
    "Roll $1$: $r_{1} \\in h$\n",
    "\n",
    "Roll $2$: $[r_{2} \\in h]$ OR $[r_{1} \\in x$ AND $r_{2} = 7]$\n",
    "\n",
    "Roll $n > 2$: $r_{n} \\in h$ OR $[r_{n-1} \\in x$ AND $r_{2} = 7]$ OR $[r_{m} = x_{i}$ AND $r_{m+1,...,n-1} = x_{j} \\in x, x_{j} \\neq x_{i}$ AND $r_{n} = 7]$\n",
    "\n",
    "The rolls on which you can win are:\n",
    "\n",
    "Roll $1$: $r_{1} \\in y$\n",
    "\n",
    "Roll $2$: $[r_{2} \\in y]$ OR $[r_{1}= x_{i} \\in x$ AND $r_{2} = x_{i}]$\n",
    "\n",
    "Roll $n > 2$: $r_{n} \\in h$ OR $[r_{1}= x_{i} \\in x$ AND $r_{2} = x_{i}]$ OR $[r_{m} = x_{i}$ AND $r_{m+1,...,n-1} = x_{j} \\in x, x_{j} \\neq x_{i}$ AND $r_{n} = x_{i}]$\n",
    "\n",
    "The probability that the we roll m rolls of $x_{j} \\neq x_{i} = \\delta$\n",
    "\n",
    "The probability that we roll $x_{i} \\in x$ twice is $\\sum_{i} x_{i}^2 = \\frac{100}{1296}$\n",
    "\n",
    "| Roll | house                  |  you                |\n",
    "|------|------------------------|---------------------|\n",
    "|  1 | 4/36 | 8/36 |\n",
    "|  2 | 4/36 + (24/36)(6/36) = 8/36 | 8/36 + 100/1296 |\n",
    "| n>2| 8/36 + (6/36)$\\delta^n$  |  8/36 + (100/1296)$\\delta^n$ |\n",
    "\n",
    "\n",
    "From the table we see that the $P(\\text{house wins})$ is greater than $P(\\text{you win})$ for Rolls > 2\n",
    "\n",
    "Therefore $\\color{red}{E[R=r | \\text{ house wins}] < E[R=r | \\text{ you win}]}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Suppose it takes \\$20 to play, and the payoff is \\$100, \\$80,\\$60, \\$40, \\$0 if you win in the 1st, 2nd, 3rd, 4th, 5th round, respectively. That is, if you win in the 1st round, you are paid \\$100 (so your net profit is \\$80, if you win in the 2nd round, you are paid \\$80, etc. Derive the expected payoff function of a game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The expected payoff function for you to win: $E(payoff)=P_1\\times 80+P_2\\times 60+P_3\\times 40+P_4\\times 20$, where $P_i$ is the probability that you win on the $i$-th roll.\n",
    "Let's calculate $P_i$ respectively:\n",
    "$$P_1=\\frac{8}{36}$$\n",
    "$$P_2=\\frac{24}{36}\\times\\frac{24}{36} $$\n",
    "$$P_3=\\frac{24}{36}\\times\\frac{6}{36}\\times\\frac{24}{36} $$\n",
    "$$P_4=\\frac{24}{36}\\times\\frac{6}{36}\\times\\frac{6}{36}\\times\\frac{24}{36} $$\n",
    "Note: the probability for any $(i-1)$-th roll without a winner is $1-\\frac{24}{36}-\\frac{6}{36}=\\frac{6}{36}$\n",
    "Thus the expected payoff is $\\color{red}{E(payoff)=47.65}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: Statistical Estimation and Statistical Inference\n",
    "\n",
    "In classical statistics, parameters are unknown constants whereas estimators are functions of samples and are random variables. The questions in this section are designed to clarify the relationship between parameters and estimators, and explore the properties that different estimators may have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Question 8  (10 Points)\n",
    "\n",
    "\n",
    "Let $Y1, ..., Y_n$ be $n$ random variables, such that any two of them are uncorrelated, and all share the same mean $\\mu$ and variance $\\sigma^2$. Let $\\overline{Y}$ be the average $Y_i$, which is also a random variable.\n",
    "\n",
    "Define the class of linear estimators of $\\mu$ by\n",
    "\n",
    "$$\\displaystyle W = \\sum_{i=1}^{n}a_iY_i $$\n",
    "\n",
    "where the $a_i$ are constants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 1. What restriction on the ai is needed for W to be an unbiased estimator of μ?\n",
    "\n",
    "We know the unbiased estimator of population mean $\\mu$ is just the sample mean $\\bar{Y}$, for $W$ to be unbiased $E(W)=\\mu$:\n",
    "\n",
    "$$E(W)=E(\\sum_{i=1}^n{a_iY_i})=\\sum_{i=1}^n{a_iE(Y_i)}$$\n",
    "\n",
    "$\\forall \\quad i \\in 1,...,n$, we have $E(Y_i)=\\mu$, plug back in:\n",
    "\n",
    "$$E(W)=\\sum_{i=1}^n{(a_i\\mu)}=\\mu\\sum_{i=1}^n{a_i}=\\mu$$\n",
    "\n",
    "thus the restriction on $a_i$ is $\\color{red}{\\sum_{i=1}^n{a_i}=1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Find $Var(W)$\n",
    "\n",
    "From $Var(W)=E(W^2)-E(W)^2$, where\n",
    "\n",
    "$$E(W^2)=E((\\sum_{i=1}^n{a_iY_i})^2)=E(\\sum_{i=1}^n\\sum_{j=1}^n{a_ia_jY_iY_j})=E(\\sum_{i=1}^na_i^2Y_i^2)+E(\\sum_{i\\neq j}{a_ia_jY_iY_j})$$\n",
    "\n",
    "thus $$E(W^2)=\\sum_i{a_i^2E(Y_i^2)}+\\sum_{i\\neq j}{a_ia_jE(Y_iY_j)}$$\n",
    "\n",
    "where $E(Y_i^2)=Var(Y_i)+E(Y_i)^2=\\sigma^2+\\mu^2$, and because any two of $Y_i$ are uncorrelated, we have $E(Y_iY_j)=E(Y_i)E(Y_j)=\\mu^2$, hence\n",
    "\n",
    "$$E(W^2)=(\\sigma^2+\\mu^2)\\sum_ia_i^2+\\mu^2\\sum_{i\\neq j}a_ia_j=\\sigma^2\\sum_ia_i^2+\\mu^2(\\sum_ia_i^2+\\sum_{i\\neq j}a_ia_j)=\\sigma^2\\sum_ia_i^2+\\mu^2(\\sum_ia_i)^2$$\n",
    "\n",
    "then we have $E(W)^2=(\\sum_i{a_iE(Y_i)})^2=\\mu^2(\\sum_ia_i)^2$, then the variance of $W$ is:\n",
    "\n",
    "$$Var(W)=E(W^2)-E(W)^2=\\color{red}{\\sigma^2\\sum_{i=1}^na_i^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Given a set of numbers $a1, a2, ...a_n$, the following inequality holds:\n",
    "\n",
    "$$\\frac{1}{n}\\big(\\sum{i=1}^{n}a_{i}\\big)^2 \\leq \\sum_{i=1}^{n}a_{i}^{2} $$\n",
    "\n",
    "#### Use this inequality, along with the previous parts of this question, to show that $Var(W) \\geq Var(\\overline{Y})$ whenever $W$ is unbiased. We say that $\\overline{Y}$ is the best linear unbiased estimator (BLUE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From variance definition and property we have $Var(\\bar{Y})=Var(\\frac{1}{n}\\sum_i{Y_i})=\\frac{1}{n^2}Var(\\sum_i{Y_i})$, in which\n",
    "\n",
    "$$Var(\\sum_i{Y_i})=\\sum{i,j=1}^n{Cov(Y_i,Y_j)}=\\sum_i{Var(Y_i)}+\\sum_{i\\neq i}{Cov(Y_i,Y_j)}$$\n",
    "\n",
    "because any pair of $Y_i$ is uncorrelated, we have $Cov(Y_i,Y_j)=0\\quad\\forall i\\neq j$, then $Var(\\sum_i{Y_i})=\\sum_i{Var(Y_i)}=n\\sigma^2$, \n",
    "thus $Var(\\bar{Y})=\\frac{1}{n^2}\\times n\\times\\sigma^2=\\frac{1}{n}\\sigma^2$\n",
    "\n",
    "from part 1, when $W$ is unbiased, we have $\\sum_ia_i=1$, then $Var(\\bar{Y})$ can be written as $\\frac{1}{n}(\\sum_ia_i)^2$,\n",
    "\n",
    "because $\\sigma^2\\geq 0$, according to the given Cauchy inequality, we have $\\color{red}{\\sigma^2\\frac{1}{n}(\\sum_ia_i)^2\\leq \\sigma^2\\sum_i{a_i^2}}$, then\n",
    "\n",
    "$$Var{\\bar{Y}}\\leq Var(W)$$\n",
    "\n",
    "whenever $W$ is unbiased, and $\\bar{Y}$ is BLUE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9 (10 Points)\n",
    "\n",
    "Let $\\bar{Y}$ denote the average of $n$ independent draws from a population distribution with\n",
    "mean $\\mu$ and variance $\\sigma^2$. Consider two alternative estimators of $\\mu$: $W1=(\\frac{n-1}{n})\\bar{Y}$ and\n",
    "$W2 = k\\bar{Y}$ , where $0 < k < 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Compute the biases of both $W_1$ and $W_2$. Which estimator is consistent?\n",
    "\n",
    "The bias $B$ of an estimator $e$ for statistic $s$ is defined as the difference between the expectation of the estimator $E(e)$ and the true value $s$ from the population, thus\n",
    "\n",
    "$$B(W_1)=E(W_1)-\\mu,$$\n",
    "\n",
    "where $$E(W_1)=E((\\frac{n-1}{n})\\bar{Y})=(\\frac{n-1}{n})E(\\bar{Y})=(\\frac{n-1}{n})\\mu$$, because the sample average $\\bar{Y}$ is the unbiased estimation population $\\mu$,\n",
    "\n",
    "thus $\\color{red}{B(W_1)=(\\frac{n-1}{n})\\mu-\\mu=-\\frac{\\mu}{n}}.$\n",
    "\n",
    "Similarly $B(W_2)=E(W_2)-\\mu$, where\n",
    "\n",
    "$E(W_2)=E(k\\bar{Y})=kE(\\bar{Y})=k\\mu$, then $$\\color{red}{B(W_2)=k\\mu-\\mu}.$$\n",
    "\n",
    "As $n$ increases, $B(W_1)$ will decreases to $0$, so $W_1$ is consistent, while $W_2$ is not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 2. Compute $Var(W_1)$ and $Var(W_2)$. Which estimator has lower variance?\n",
    "\n",
    "In general $Var(X)=E(X^2)-E(X)^2$, so we need $E(W_1^2)$ and $E(W_2^2)$:\n",
    "\n",
    "$$E(W_1^2)=E((\\frac{n-1}{n})^2\\bar{Y}^2)=(\\frac{n-1}{n})^2E(\\bar{Y}^2)$$\n",
    "$$E(W_2^2)=E(k^2\\bar{Y}^2)=k^2E(\\bar{Y}^2)$$\n",
    "\n",
    "where $E(\\bar{Y}^2)=Var(\\bar{Y})+E(\\bar{Y})^2$,\n",
    "\n",
    "then $Var(\\bar{Y})=Var(\\frac{1}{n}\\sum_i{X_i})=\\frac{1}{n^2}Var(\\sum_i{X_i})$.\n",
    "\n",
    "Because $X_i$ are independent draws, $Var(\\sum_i{X_i})=\\sum_i{Var(X_i)}=n\\sigma^2$, then $Var(\\bar{Y})=\\frac{1}{n^2}\\times n\\times \\sigma^2=\\frac{\\sigma^2}{n}$\n",
    "\n",
    "And we can obtain $E(\\bar{Y}^2)=\\frac{\\sigma^2}{n}+\\mu^2$, plug it back to get $E(W_1^2)$ and $E(W_2^2)$:\n",
    "\n",
    "$$E(W_1^2)=(\\frac{n-1}{n})^2\\times (\\frac{\\sigma^2}{n}+\\mu^2)$$\n",
    "$$E(W_2^2)=k^2\\times (\\frac{\\sigma^2}{n}+\\mu^2)$$\n",
    "\n",
    "Finally we have $Var(W_1)$ and $Var(W_2)$:\n",
    "\n",
    "$$Var(W_1)=E(W_1^2)-E(W_1)^2=(\\frac{n-1}{n})^2\\times (\\frac{\\sigma^2}{n}+\\mu^2) - (\\frac{n-1}{n})^2\\times\\mu^2 = \\color{red}{\\frac{(n-1)^2}{n^3}\\sigma^2}$$\n",
    "$$Var(W_2)=E(W_2^2)-E(W_2)^2=k^2\\times (\\frac{\\sigma^2}{n}+\\mu^2) - (k\\mu)^2=\\color{red}{\\frac{k^2}{n}\\sigma^2}$$\n",
    "\n",
    "To compare the two variations, we compare $\\frac{(n-1)^2}{n^3}$ and $\\frac{(kn)^2}{n^3}$, thus if $(n-1)>nk$, $Var(W_1)>Var(W_2)$, otherwise $Var(W_1)\\leq Var(W_2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10 (10 Points)\n",
    "\n",
    "Given a random sample $Y_1, Y_2,...,Y_n$ from some distribution $F(.)$ with mean $\\mu$ and variance $\\sigma^2$, where both $\\mu$ and $\\sigma^2$ are unknown parameters.\n",
    "\n",
    "Let $\\bar{Y}$ be the average of the sample. Consider the following estimator for $\\sigma^2$:\n",
    "\n",
    "$$\\hat{\\sigma^2}=\\frac{1}{n}\\sum_{i=1}^n{(Y_i-\\bar{Y})^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Show that $E(\\bar{Y}) = E(Y_i)  \\forall i \\in 1,2,...,n$\n",
    "\n",
    "$E(\\bar{Y})=E(\\frac{1}{n}\\sum_{i=1}^n{Y_i})=\\frac{1}{n}\\sum_{i=1}^n{E(Y_i)}$, considering $\\forall i \\quad E(Y_i)=E(Y)$, we have\n",
    "\n",
    "$E(\\bar{Y})=\\frac{1}{n}\\sum_{i=1}^n{E(Y)}=\\frac{1}{n}\\times n\\times E(Y)=E(Y_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Show that $Var(\\bar{Y}) = \\frac{1}{n}Var(Y_i) \\quad \\forall i \\in 1,2,...,n$,\n",
    "\n",
    "$Var(\\bar{Y})=Var(\\frac{1}{n}\\sum_i{Y_i})=\\frac{1}{n^2}Var(\\sum_i{Y_i})$ where\n",
    "\n",
    "$Var(\\sum_i{Y_i})=\\sum_{i=1}^n{Var(Y_i)}+\\sum_{i\\neq j}{Cov(Y_i,Y_j)}$\n",
    "\n",
    "because the sample is randomly drawn, applying $\\color{red}{i.i.d}$ property, we have $Cov(Y_i,Y_j)=0$\n",
    "\n",
    "and since $\\forall i \\quad Var(Y_i)=Var(Y)$\n",
    "\n",
    "thus $Var(\\bar{Y})=\\frac{1}{n^2}\\sum_{i=1}^n{Var(Y_i)}=\\frac{1}{n^2}\\times n\\times Var(Y)=\\frac{1}{n}Var(Y_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Compute the expectation of $\\hat{\\sigma^2}$ in terms of n and $\\sigma^2$. In your derivation, make sure make use of the $i.i.d$ property and identify where you use it.\n",
    "\n",
    "Let's massage $\\hat{\\sigma^2}$ first:\n",
    "\n",
    "$$\\hat{\\sigma^2}=\\frac{1}{n}\\sum_{i=1}^n{((Y_i-\\mu)-(\\bar{Y}-\\mu))^2}=\\frac{1}{n}\\sum_i{((Y_i-\\mu)^2+(\\bar{Y}-\\mu)^2-2(Y_i-\\mu)(\\bar{Y}-\\mu))}$$\n",
    "\n",
    "expand the summation, we have:\n",
    "\n",
    "$$\\hat{\\sigma^2}=\\frac{1}{n}\\sum_i(Y_i-\\mu)^2+(\\bar{Y}-\\mu)^2-\\frac{1}{n}\\sum_i{(2(Y_i-\\mu)(\\bar{Y}-\\mu))}$$\n",
    "\n",
    "the first summation term is the definition of $\\sigma^2$, we further expand the last summation:\n",
    "\n",
    "$$\\hat{\\sigma^2}=\\sigma^2+(\\bar{Y}-\\mu)^2-\\frac{2(\\bar{Y}-\\mu)}{n}\\sum_i{(Y_i-\\mu)}$$\n",
    "\n",
    "with $\\sum_i{Y_i}=n\\bar{Y}$:\n",
    "\n",
    "$$\\hat{\\sigma^2}=\\sigma^2+(\\bar{Y}-\\mu)^2-\\frac{2(\\bar{Y}-\\mu)}{n}(n\\bar{Y}-n\\mu)=\\sigma^2-(\\bar{Y}-\\mu)^2$$\n",
    "\n",
    "now take expectation:\n",
    "\n",
    "$$E(\\hat{\\sigma^2})=E(\\sigma^2)-E((\\bar{Y}-\\mu)^2)=\\sigma^2-E(\\bar{Y}^2)-\\mu^2+2\\mu E(\\bar{Y})$$\n",
    "\n",
    "from (1): $E(\\bar{Y})=E(Y_i)=\\mu$, we have:\n",
    "\n",
    "$$E(\\hat{\\sigma^2})=\\sigma^2+\\mu^2-E(\\bar{Y}^2)$$\n",
    "\n",
    "where $E(\\bar{Y}^2)=Var(\\bar{Y})+E(\\bar{Y})^2$, from (2), we have:\n",
    "\n",
    "$$E(\\bar{Y}^2)=\\frac{\\sigma^2}{n}+\\mu^2$$\n",
    "\n",
    "plug back in, the expectation of $\\hat{\\sigma^2}$:\n",
    "\n",
    "$$\\hat{\\sigma^2}=\\sigma^2+\\mu^2-\\frac{\\sigma^2}{n}-\\mu^2=\\color{red}{\\frac{n-1}{n}\\sigma^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Is this an unbiased estimator for $\\sigma^2$?\n",
    "\n",
    "Obviously **it is a biased estimator**, as we see its expectation is a fraction $\\frac{n-1}{n}$ of the truth $\\sigma^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 5. If not, what function of $\\hat{\\sigma^2}$ produce an unbiased estimator?\n",
    "\n",
    "To become unbiased, we simply multiply $\\frac{n}{n-1}$ on $\\hat{\\sigma^2}$, and the unbiased estimator is:\n",
    "\n",
    "$$\\color{red}{\\frac{1}{n-1}\\sum_{i=1}^n{(Y_i-\\bar{Y})^2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11 (5 Points)\n",
    "\n",
    "For positive random variables $X$ and $Y$, suppose the expected value of $Y$ given $X$ is $E(Y|X)=\\theta X$\n",
    "The unknown parameter $\\theta$ shows how the expected value of $Y$ changes with $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Define the random variable $Z=Y/X$. Show that $E(Z)=\\theta$.\n",
    "Evaluate $E(Z|X)=E(Y/X|X)=E(Y|X)/X=(\\theta X)/X=\\theta$, thus\n",
    "\n",
    "$$\\color{red}{E(Z)=E(E(Z|X))=E(\\theta)=\\theta}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Use part (1) to prove that the estimator $W_1=\\frac{1}{n}\\sum_{i=1}^n{(Y_i/X_i)}$ is unbiased for $\\theta$, where\n",
    "${(X_i,Y_i): i = 1, 2, ..., n}$ is a random sample.\n",
    "\n",
    "Evaluate $E(W_1)=\\frac{1}{n}\\sum_{i=1}^n{E((Y_i/X_i))}$, from (1) we have\n",
    "\n",
    "$$\\color{red}{E(W_1)=\\frac{1}{n}\\sum_{i=1}^n{E(Z_i)}=\\frac{1}{n}\\times n\\times\\theta=\\theta}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3. Explain why the estimator $W2=\\bar{Y}/\\bar{X}$ , where the overbars denote sample averages, is\n",
    "not the same as $W_1$. Nevertheless, show that $W_2$ is also unbiased for $\\theta$.\n",
    "\n",
    "Expand $W_2=\\frac{n^{-1}\\sum_iY_i}{n^{-1}\\sum_iX_i}=\\frac{\\sum_iY_i}{\\sum_iX_i}$, the summation can't be further simplified, obviously $W_1\\neq W_2$.\n",
    "\n",
    "Evaluate $E(W_2)=E(\\frac{\\sum_iY_i}{\\sum_iX_i})$, apply expectaion within the summation, we have:\n",
    "\n",
    "$$\\color{red}{E(W_2)=\\frac{\\sum_i{E(Y_i)}}{\\sum_i{E(X_i)}}=\\frac{\\sum_i{E(Y)}}{\\sum_i{E(X)}}=\\frac{E(Y)}{E(X)}=\\frac{E(Y|X)}{E(X|X)}=\\frac{\\theta X}{X}=\\theta}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12 (10 Points)\n",
    "You are hired by the governor to study whether a tax on liquor has decreased average liquor\n",
    "consumption in your state. You are able to obtain, for a sample of individuals selected at\n",
    "random, the difference in liquor consumption (in ounces) for the years before and after the\n",
    "tax. For person $i$ who is sampled randomly from the population, $Y_i$ denotes the change in\n",
    "liquor consumption. Treat these as a random sample from a Normal $(\\mu,\\sigma^2)$ distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. The null hypothesis is that there was no change in average liquor consumption. State this formally in terms of $\\mu$.\n",
    "Null hypothesis: $\\color{red}{H_0: \\mu=0}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. The alternative is that there was a decline in liquor consumption; state the alternative in terms of $\\mu$.\n",
    "Alternative hypothesis: $\\color{red}{H_1: \\mu<0}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Now, suppose your sample size is $n=900$ and you obtain the estimates $\\bar{y}=-32.8$ and $s=466.4$. Calculate the $t$ statistic for testing $H_0$ against $H_1$; obtain the $p$-value for the test. Do you reject $H_0$ at the $5\\%$ level? At the $1\\%$ level?\n",
    "\n",
    "The $t$ statistic:\n",
    "\n",
    "$$\\color{red}{t=\\frac{\\bar{y}-\\mu_0}{s/\\sqrt{n}}=\\frac{-32.8-0}{466.4/\\sqrt{900}}=-2.11}$$\n",
    "\n",
    "$p$-value: $$\\color{red}{p=0.0176}$$\n",
    "\n",
    "Reject $H_0$ at the $5\\%$ level, and fail to reject $H_0$ at the $1\\%$ level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Would you say that the estimated fall in consumption is large in magnitude? Comment on the practical versus statistical significance of this estimate.\n",
    "For practical significance since we are using a paired-sample t-test, we evaluate the Cohen's $d$ effect size:\n",
    "\n",
    "$$\\color{red}{d=\\frac{\\bar{y}-\\mu}{s}=0.070}$$\n",
    "\n",
    "thus there is **little practical significance** from the test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 5. What has been implicitly assumed in your analysis about other determinants of liquor consumption over the two-year period in order to infer causality from the tax change to liquor consumption?\n",
    "It is implicitly assumed that ​*before*​ and ​*after*​ the tax law is implemented, all other determinants that can affect liquor consumption remain the same, thus the difference is only attribted to tax change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13 (10 Points)\n",
    "The ​*New York Times*​ (2/5/90) reported three-point shooting performance for the top 10\n",
    "three-point shooters in the NBA. The following table summarizes these data:\n",
    "\n",
    "| Player | FGA-FGM |\n",
    "|--------|---------|\n",
    "| Mark Price | 429-188 |\n",
    "| Trent Tucker | 833-345 |\n",
    "| Dale Ellis | 1149-472 |\n",
    "| Craig Hodges | 1016,396 |\n",
    "| Danny Ainge | 1051-406 |\n",
    "| Byron Scott | 676-260 |\n",
    "| Reggie Miller | 416-519 |\n",
    "| Larry Bird | 1206-455 |\n",
    "| Jon Sundvold | 440-166 |\n",
    "| Brian Taylor | 417-157 |\n",
    "\n",
    "For a given player, the outcome of a particular shot can be modelled as a Bernoulli (zero-one)\n",
    "variable: if $Y_i$ is the outcome of shot $i$, then $Y_i=1$ if the shot is made, and $Y_i=0$ if\n",
    "the shot is missed. Let $\\theta$ denote the probability of making any particular three-point shot\n",
    "attempt. The natural estimator of $\\theta$ is $\\bar{Y}=FGM/FGA$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Estimate $\\theta$ for Mark Price.\n",
    "$$\\color{red}{\\theta_{MP}=\\frac{188}{429}=0.4382}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Find the standard deviation of the estimator $\\bar{Y}$ in terms of $\\theta$ and the number of shot attempts, $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. The asymptotic distribution of $(\\bar{Y}-\\theta)/se(\\bar{Y})$ is standard normal, where $se(\\bar{Y})=\\sqrt{\\bar{Y}(1-\\bar{Y})/n}$.  Use this fact to test $H_0: \\theta= .5$ against $H_1: \\theta < .5$ for Mark Price. Use a $1\\%$ significance level.\n",
    "\n",
    "For Mark Price: $se(\\bar{Y})=\\sqrt{\\frac{0.4382(1-0.4382)}{429}}=0.0240$, and $\\frac{\\bar{Y}-\\theta}{se(\\bar{Y})}=\\frac{0.4382-0.5}{0.0240}=-2.5786$, $p$-value $=0.005$, thus we reject $H_0$ at $1\\%$ level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Define Type I error.\n",
    "Type I error is the probability that $H_0$ is falsely rejected given it's true, $P(\\text{reject } H_0 | H_0)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What is the probability of Type I error of this test?\n",
    "At $1\\%$ leve, the Type I error is $\\color{red}{\\alpha=1\\%}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Define Type II error.\n",
    "Type II error is the probability of failing to reject $H_0$ given that $H_1$ is true, namely $P(\\text{fail to reject } H_0|H_1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. What is the probability of Type II error when using this decision rule, assuming the ”true” population proportion is $\\theta^∗ = 0.45$.\n",
    "For $1\\%$ level to reject $H_0$, the decision rule: $\\frac{\\bar{Y}-0.5}{se(\\bar{Y})}<Z_{0.01}=-2.3263$, or $\\bar{Y}<Z_{0.01}*se(\\bar{Y})+0.5=0.4442$\n",
    "\n",
    "with true $\\theta^*=0.45$:\n",
    "\n",
    "$$\\beta=P(\\bar{Y}\\leq 0.4442|\\theta=0.45)=P(Z\\leq \\frac{0.4442-0.45}{se(\\bar{Y})})=\\color{red}{0.4040}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Define the power of the test (in general terms).\n",
    "Power of a test is the probability that $H_0$ is rejected given that $H_1$ is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Calculate the power of this test, again assuming the ”true” population proportion is $\\theta^∗ = 0.45$.\n",
    "The **power of the test** (given $\\theta^*=0.45$) is: $1-\\beta=\\color{red}{0.5960}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
