---
title: "MIDS W271-4 Lab 3"
author: "Lei Yang, Ron Cordell"
date: "April 23, 2016"
output:
  pdf_document:
    includes:
      in_header: header.tex
---

```{r setup, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = FALSE)
knitr::read_chunk('lab3-part1.R')
```

# Part 1 - Modeling House Values

## Exploratory Data Analysis

An examination of the provided data set reveals 11 variables of which _withWater_ is binary and rest are continuous. There are no NA's in the data set, however the _distanceToHighway_ variable appears to have a coding issue. We'll examine this variable in more detail a bit later, but first we summarize the variables in the following table.

```{r part1setup, echo=FALSE,warning=FALSE, message=FALSE, warning=FALSE, results='hide'}
```
```{r summary_latex, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
```

For the purposes of this analysis we categorize the variables _crimeRate_pc_, _nonRetailBusiness_, _withWater_, _distanceToCity_, _distanceToHighway_, _pollutionIndex_, _pupilTeacherRation_ and _pctLowHousing_ to be environmental variables. The variables _ageHouse_ and _nBedRooms_ are attributes of the house. The variable _homeValue_ is the dependent variable we would like to explain in terms of primarily the environment variables but we will compare to explanations in terms of house attributes as well.

In the next several pages we examine the distribution of each of the variables and, where indicated, the distribution of the transformed as well.

\newpage
```{r data_transformations, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
```

```{r histogram_of_crimerate, echo=FALSE, warning=FALSE, fig.width=6.5, fig.height=8}
```

The distribution of _crimeRate_pc_ is highly right-skewed with a very long tail. This makes sense as most neighborhoods are very low crime neighborhoods. The distribution of _log(crimeRate_pc)_ appears almost bi-modal; however the analysis of skew and kurtosis show a significant improvement of each with a log transformation.
\newpage
```{r histogram_of_nonbizretail, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.5, fig.height=6}
```

The variable _nonRetailBusiness_ is a measure of the footprint of industy in a neaghborhood. This may range from light industrial to manufacturing but that information is not given. The distribution of _nonRetailBusiness_ shows a spike at 0.18 business-acres but is otherwise somewhat uniform. There was no transform that improved skew or kurtosis for this variable.
\newpage
```{r histogram_of_agehouse, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.5, fig.height=8}
```

The variable _ageHouse_ is the percentage of houses in a neighborhood built before 1950 and shows a significant left-skew with a long tail to the left. Subtracting the variable from 100% transforms it from percentage of houses built before 1950 to percentage of houses built after 1950, giving a left skewed distribution. Taking the log of the distribution helps remove the skew.

\newpage

```{r histogram_of_distcity, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.5, fig.height=8}
```

The _distanceToCity_ variable shows a right-skewed distrubution that is much improved by a log transformation.
\newpage
```{r histogram_of_disthiway, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.5, fig.height=4}
```

The _distanceToHighway_ variable shows the concern with coding error in this histogram as there is a large occurance of the value _24_. About 25% of the dataset have this value, some of which may be correct but it seems unlikely that the _distanceToHighway_ variable would be much greater than the _distanceToCity_ variable.

\newpage

The _pupilTeacherRatio_ variable shows a roughly uniform distribution except for a large number of occurances of the value _23_, which must be a more common classroom size.

```{r histogram_teacherpupil, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.5, fig.height=8}
```

The series is transformed by inverting the ratio to become a Teacher to Pupil ratio, then taking the log.

\newpage
```{r histogram_of_lowincome, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.5, fig.height=8}
```

The _pctLowIncome_ variable has a right-skewed distribution that tapers off to the right relatively quickly. A log transformation greatly improves the skew and kurtosis of the distribution.

\newpage
```{r histogram_of_homevalue, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.5, fig.height=8}
```

The _homeValue_ variable shows a slight right-skew and a log transformation is used to help with this. It also allows discussion in terms of percentage change of home value when controlling for other variables.

\newpage
```{r histogram_of_pollution, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.5, fig.height=9}
```

The _pollutionIndex_ variable shows a right-skewed distribution upon which we perform a log transform.
\newpage
```{r histogram_of_nbeds, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.5, fig.height=4.5}
```

The _nBedRooms_ variable appears amazingly normal-like in its distribution.

The next page brings all the variables into a single matrix for comparison and to get a first look at correlations to explore further.
\newpage
\blandscape
```{r matrixplot_variables, echo=FALSE, message=FALSE, warning=FALSE, fig.width=9.5, fig.height=7.0}
```
\elandscape

```{r disthiway_detail, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
```

### DistanceToHighway Variable Detailed Examination

We saw previously that the _distanceToHighway_ variable looked suspicious so in this section we look at how to address a possible coding issue. The number of rows in the dataset that have the _distanceToHighway_ variable as 24 is 25% of the dataset. Removing these rows would remove a significant amount of data, reducing _N=400_ to _N=296_. We examine two strategies and compare them to the row-removal option: replacing values of 24 with the mean of the filtered values or with the value of _distanceToCity_.

The following two tables compare the summaries of the filtered dataset with the summaries of the dataset with transformed values. Comparing the _distanceToHighway_meanMod_ and _distanceToHighway_cityMod_ shows that the latter is much closer to the values of the filtered dataset. This indicates that replacing the value of 24 with the value of _distanceToCity_ is a reasonable transformation to deal with the coding issue. The idea is further substantiated by the proposition that the distance to a city is usually not greater than the distance to a highway as cities are generally located on highways.  

The following page shows a set of comparison histograms for the _distanceToHighway_ variable with the different transformations. A histogram of _distanceToCity_ is included as a reference.  



```{r histogram_of_disthiway2, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.5, fig.height=4.5}
```
\newpage

```{r disthiway_comparison_latex, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
```
```{r disthiway_histograms, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.5, fig.height=6.0}
```

\newpage
\blandscape
```{r matrixplot_withvariablemods, echo=FALSE, message=FALSE, warning=FALSE, fig.width=9.5, fig.height=7.0}
```
\elandscape
\newpage

## Multivariate Data Analysis

First we will examine the relationships of the environment variables on home values graphically. We can see that there are definitely relationships between most of the environmental variables and home values, as shown on the next two pages of graphs.

```{r multivariate-relationships-env1, echo=FALSE, message=FALSE, warning=FALSE, fig.width=3.25, fig.height=3.75}
```
\newpage

```{r multivariate-relationships-env2, echo=FALSE, message=FALSE, warning=FALSE, fig.width=3.25, fig.height=3.75}
```
\newpage

These final two graphs show relationships between home attributes and home values.

```{r multivariate-relationships-attr1, echo=FALSE, message=FALSE, warning=FALSE, fig.width=3.25, fig.height=3.75}
```
\newpage

## Models Incorporating Environment Variables

The linear regression models are built towards increasing saturation where collinearity was not introduced that biases the model. Of all the environment parameters _pollutionIndex_ and _nonRetailBusiness_ added increased collinearity in the model. In fact, the _pollutionIndex_ estimated coefficient was not distinguishable from 0 and was subsequently left out of the more saturated models. A similar situation occurred with the _nonRetailBusiness_ variable.

The saturated regression model for environmental variables is expressed as:

$$log(homeValue) = 15.5784 + 0.5128 log(TeacherPupilRatio) + 0.1193 distanceToHighway$$
$$ + 0.025 withWater - 0.0192 log(crimeRate\_pc) - 0.4238 log(lowIncomeHousing)$$

**Teacher:Pupil Ratio**: more teachers per pupil is correlated with increased home values. However it is not possible to tell if an area with higher value homes can afford to hire more teachers or if more teachers makes for better schools which attract more affluent families. A 1% increase in the Teacher to pupil ration will result in a 1/2% increase in the home values, holding the other variables constant.

**Distance To Highway**: Interestingly, a longer distance to highway is correlated with higher home values. An increase of 1 mile in the distance results in the increase of about 1/10% of the average value of a home, controlling for the other variables in the model.

**Close To Water**: On average, home values increase by .025% if the home is within 5 miles of water when controlling for other variables in the model. While this result is statistically significant it is not practically significant. One can imagine that homes actually "on the water" have higher values than those that aren't. However the practical significance of being close to a body of water is small.

**Crime Rate**: Unsurprisingly, crime rate has a negative effect on average home value. An increase of 1% in the crime rate results in a reduction in average home value of about .02%, controlling for the other variables. This may not seem like very much, but crime rates tend to be very low in the areas with the highest home values. A doubling of the crime rate from 1 per 1000 to 2 per 1000 results in a 100% increase in the crime rate and a 2% reduction in price. Because this is a non-linear relationship we can't take extrapolate much further but the general idea is apparent.

**Low Income Housing**: Low income housing is an obvious correlator for average home values. However we can imagine that while the numeric averages are reduded as lower income housing increases in an area the effect of higher concentrations of low income housing tends to pull down home values within a certain distance. Controlling for the other variables in the model, an increase of 1% in low income housing can decrease average home values in the area by about 1/2%.

**Distance To City**: It is interesting that _distanceToCity_ did not factor into our models. It is highly correlated with the _crimeRate_pc_ variable in that the closer to the city the higher the crime rate.

This model only reflects the correlations of a small group of environment variables on the average price of a home. It is not a model to predict the average price of a home given these factors. This model gives some ideas about how some factors could affect the average values of homes in the area, however. Some biases in the model include the correlation between the low income housing and home values. It is difficult to use that observation as an indicator for other things like the type of people in the area, the extent to which social services are offered, or how the type of housing interacts with crime rate.

```{r modeling, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
```
\blandscape
```{r model_comparison_latex, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
```
\elandscape

Finally we examine the residual plots to diagnose the selected model, we can see that the assumptions of normality, zero-condition mean, and homoskedasticity can be held for the model.

```{r model_diagnostics, echo=FALSE, warning=FALSE, fig.width=6.5, fig.height=8.0}
```

```{r setup2, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = FALSE)
knitr::read_chunk('lab3-part2.R')
```

```{r part2_setup, echo=FALSE, message=FALSE, warning=FALSE, results='hide}
```

# Part 2 - Modeling and Forecasting a Real-World Macroeconomic Financial Time Series

## Exploratory Data Analysis

In order to better understand the time series and analyze the possible underlying processes we must first observe and explore the time series. A summary of the time series is:

```{r part2_loaddata, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
```
```{r part2_summarize_data_latex, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
```

The first set of plots reveals:

* The series is non-stationary; it has a persistent upward trend, interrupted by shocks;
* There are shocks at approximately time periods 500, 1200, 1800 and 2200;
* There appears to be seasonality in the series;
* The autocorrelation shows a very slight decay over the entire correlagram;
* The partial autocorrelation shows barely significant results at lags 14 and 32;
* We do not know the frequency of the time series;
* The series is of closing prices of DXCM

To remove the trend from the series we take the first difference and replot to check the results.

```{r part2_diff_calcs, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
```

```{r part2_summarize_diff_data_latex, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
```

In the differenced series we observe:

* The first difference series has a more or less white noise appearance until approximately time interval 1600 where the volatility of the series increases dramatically. This corresponds to the sudden, persistent upward trend in the original series.
* The autocorrelation shows marginally significant results at lags 13, 15, 16, 24, 31
* The partial autocorrelation shows a cyclic behavior that doesn't appear to decline, with significant results at lags 11, 13, 14, 15, 16, 24, 25, 31

\newpage
```{r part2_tsplots, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.5, fig.height=8.0}
```

\newpage
```{r part2_diff_plots, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.5, fig.height=8.0}
```
\newpage

We also examine the first difference of the log of the series and replot to check results. In the differenced log series we observe:

* The volatility appears to be reversed such that it is around interval 300-500, and overall the volatility of the differenced log series is higher.
* The ACF shows only a small results at lag 15 and 20.
* The PACF shows a cyclic behavior with significant results at lags 9, 15, 20

```{r part2_difflog_calcs, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
```
```{r part2_difflog_plots, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.5, fig.height=7.0}
```
\newpage

The seasonality of the series is not strong in the ACF of the differenced series. However, there are hints of a 5 day cycle that corresponds to the weekly frequency. There are stronger spikes that appear in lags 15 and 30 that support a multiple or harmonic of 5.

The ACF and PACF of the differenced seasonal series show evidence of an underlying MA(5) process

```{r part2_seasonal_calcs, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
```
```{r part2_seasonal_plots, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.5, fig.height=7.0}
```
\newpage

## Model Selection

We use the `get.best.arima` function from the async materials and the Introductory Time Series with R book [Cowpertwait, Metcalfe - 2009] to perform a search for the best ARIMA model. The procedure results in an ARIMA(0,1,0) estimated model.


```{r part2_models, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
```
```{r part2_arima_summary_latex, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
```
```{r part2_model_plot_ts, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.5, fig.height=6.5}
```

\newpage
```{r part2_model_residual_plots, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.5, fig.height=7.0}
```

The residuals show an increased volatility at the right end of the residuals graph, and the PACF of the squared residuals shows definite autocorrelation of the residuals.

The ARIMA(0,1,0) model of the captures a good deal of the time series' behavior and it is a very parsimonious model.

Since the residuals of the ARIMA(0,1,0) model shows time-dependency we fit a GARCH model to the residual of the ARIMA model. The result is a GARCH(1,1) model where all parameters are significant. We fail to reject the hypothesis that the residuals are IID based on the results of the Ljung-Box test on the squared residuals. The summary of the GARCH model output is shown below.

```{r part2_garch_model, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
```
```{r part2_garch_model_residual_plots, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.5, fig.height=7.0}
```
\newpage
```{r part2_garch_model_table_latex, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
```
```{r part2_garch_model_summary, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.5, fig.height=7.0}
```

The complete ARIMA(0,1,0)-GARCH(1,1) model looks like:

$$y_{t}-y_{t-1} = .010761 + .153134 \epsilon_{t-1}^{2}+ .805974 \hat{h}_{t-1}$$

All of these models exhibit time-dependent residuals so we fit a GARCH model to the residuals of the resulting model
\newpage

```{r part2_forecast_model, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
```
```{r part2_forecast_plot, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.5, fig.height=7.0}
```

\newpage
```{r setup3, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = FALSE)
knitr::read_chunk('lab3-part3.R')
```

# Part 3 - Forecast Web Search Activity for "Global Warming"

```{r part3_loaddata, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
```

## Exploratory Data Analysis

The time series is a weekly measurement of the frequency of a search phrase over a period from 1/4/2004 to 1/24/16 and we have no other information. The plot reveals that from 2004 to around 2012 there is very little activity; after 2012 the activity begins increasing persistently at a steep rate.

```{r part3_summarize_data_latex, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
```
```{r part3_ts_initial_plot, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.5, fig.height=6.5}
```
\newpage
We can fit a model that does a better job of forecasting if we take that part of the series that contains the data since about 2012 on which to estimate a model. An analysis of the series indicates that the split point is around 2011. We split the series into 2004-2010 and 2011-2016 in order to capture the variation in the later part of the model. We measure this by observing the autocorrelation in each portion of the series to minimize the autocorrelation in the early series and maximize it in the later series.

The following two pages show the comparative time series plots, ACF and PACF for the early and later time series.

```{r part3_ts_extract, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
```
```{r part3_compare_ts_latex, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
```
\newpage
```{r part3_plots_ts1, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.5, fig.height=6.5}
```
\newpage
```{r part3_plots_ts2, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.5, fig.height=6.5}
```
\newpage

## Time Series 2011-2015 Data Exploration

We can see from the plots on the previous page that the time series is not stationary. It has a persistent trend and exhibits seasonality with an increasing variance. We first examine the first difference of the series.

```{r part3_ts2_diff_calc, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
```
```{r part3_plots_ts2_diff, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.5, fig.height=6.5}
```

The resulting differenced series has increasing volatility over time. The ACF is indicative of an AR(2) process and the PACF indicates an MA process as well.
\newpage

The seasonal component is present and seems to be in multiples of 4 and 13.

```{r part3_seasonal_diff, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
```
```{r part3_seasonal_plot, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.5, fig.height=6.5}
```
\newpage

## Modeling

We use the `auto.arima` function to estimate the best SARIMA model and we obtain a SARIMA(1,1,1)(0,1,1)[52].

```{r part3_model, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
```
```{r part3_model_plot_ts, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.5, fig.height=6.5}
```
\newpage
```{r part3_model_residual_plots, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.5, fig.height=6.5}
```
\newpage

Garch model

```{r part3_garch, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
```
```{r part3_garch_residual_plots, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.5, fig.height=6.5}
```

## Forecast


```{r part3_forecast, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
```
```{r part3_forecast_plot, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.5, fig.height=6.5}
```



\newpage
```{r setup4, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = FALSE)
knitr::read_chunk('lab3-part4.R')
```

```{r part4_setup, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
```

```{r part4_loaddata, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
```

# Part 4 - Forecast Inflation-Adjusted Gas Price

## Exploratory Data Analysis

The _gasOil_ series consists of 410 observations of two variables, _Production_ and _Price_. As described the _Production_ variable is in units of Million Barrels of Oil and _Price_ is in inflation adjusted US Dollars. The observations are monthly beginning 1978/1/1 and ending 2012/2/1. The plots of the two variables indicate that both series appear similar to random walks: they have varying trends up and down over time. The _Production_ series appears to have a seasonal component. The _Price_ series may have a seasonal component as well but it isn't as prominent. A scatterplot of the two variables does not reveal any obvious correlation.


```{r part4_create_ts, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
```
```{r part4_plot_ts, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.5, fig.height=6.0}
```
\newpage
```{r part4_plot_qplot, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.5, fig.height=4.0}
```

```{r part4_diff_series, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
```

### Change in Production and Change in Price

We take the difference of each series in order to compate the change in production to the change in price. We also scale the two variables so as to have zero mean and a standard deviation of 1.0 to make them more comparable. Now the scatterplot appears as a cluster about the origin of the graph.

```{r part4_summarize_diff_data_latex, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
```
```{r part4_differenced_plots, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.25, fig.height=6.0}
```
\newpage

```{r part4_differenced_qplot, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.25, fig.height=4.0}
```

## Model Recreation

The AP analysis states that there is no statistically significant correlation between oil production and gas prices. We can reconstruct a means of measuring a correlation and its significance using linear regression. We perform a regression on both the _Production_ and _Price_ variables as well as the _Change in Production_ and _Change in Price_. The results of the regressions are summarized in the table, below.

The regression on the _change in production_ and the _change in price_ shows a marginally significant p-value but only at the $\alpha=0.1$ level. The standard error shows that the estimate range crosses 0 so it is not distinguishable from 0.  As expected all regression coefficients are not distinguishable from 0 and this reproduces the AP analysis conclusion that there is no statistically significate correlation between the two variables.

### Critique

Comparing _Price_ and _Production_ in this way does not take into account the dependency on time. Each variable has it's own seasonal effects and its own volatility. A more careful analysis would compare the variables as time series and analyse the lagged relationships and seasonal factors.

```{r part4_lm, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
```
\blandscape
```{r part4_summarize_regression_models_latex, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
```
\elandscape

## Time Series Analysis

Observations of the _Price_ series are:

* The series appears like a random walk; it has periods when it is trending down and other periods when it trends up but it is not a constant trend in either direction.
* The autocorrelation plot shows very high autocorrelation and the partial autocorrelation shows very little lagged correlation. It appears that it could be a AR() underlying process but may have a small MA() component.

```{r part4_pricets_summary, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
```
```{r part4_plots_ts_price, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.25, fig.height=6.0}
```
\newpage

We calculated the differenced time series previously and we show the plots for the _Price_ variable here for analysis. There appears to be a seasonal component in the ACF at around 6 lags.

```{r part4_price_diff_plots, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.25, fig.height=6.0}
```

\newpage

## Model Estimation

Using the `auto.arima` function in R we obtain an estimated ARIMA(1,1,3) model with no seasonal components. The estimated coefficients of the model are tabulated and plots of the resulting residuals and residual autocorrelation are shown. The residuals from the estimated ARIMA(1,1,3) model show a time dependency for which we can fit a GARCH model.

```{r part4_model_price, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
```

```{r part4_arima_residuals_plot, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6.25, fig.height=6.0}
```
\newpage

Estimating the GARCH model on the residuals of the ARIMA(1,1,3) model we obtain a GARCH(1,1) model. The residuals of the GARCH model are shown and exhibit no correlation or time dependency and the Box-Ljung test indicates we are unable to reject the null hypothesis of an IID residual series.
